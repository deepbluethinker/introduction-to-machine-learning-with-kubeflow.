[[who_is_kubeflow_for_ch]]
== What does Kubeflow solve & who’s it for, and how to get started


Put some introductory text here.

=== Who is this for?

Kubeflow is for data scientist and data engineers who wish to avoid the difficulty updating their model with new data, or moving from their laptop to production.
Kubeflow does this by offering a variety of tools in one place, more than just Tensorflow, for all the different stages of a models life (data exploration, feature prep, model training, model serving, and model testing).

[TIP]
====
We talk about who this book is for in <<assumptions_about the audience>> as well as the required background and resources to get up to speed if you need them.
====




=== Brief Alternatives to Kubeflow

[[breif_kubeflow_design_and_core_components]]
=== Brief Kubeflow’s design & core components

In the machine learning landscape, there are many diverse tool sets and frameworks. Kubeflow does not seek to reinvent the wheel or provide a "one size fits all" solution - instead, it allows machine learning practitioners to compose and customize their own stacks based on specific needs. It is designed to simplify the process of building and deploying machine learning at scale; allowing data scientists to do their jobs without worrying about the "boring parts" of building the infrastructure.

Kubeflow seeks to tackle the problem of simplifying machine learning through three aspects: composability, portability, and scalability.

* Composability - the core components come from data science tools that are already familiar to machine learning practictioners. They can be used independently to facilitate specific stages of machine learning, or composed together to form end-to-end pipelines. 

* Portability - taking advantage of Kubernetes and cloud-native microservices, Kubeflow does not require you to anchor to any particular platform. You can develop and prototype on your laptop, and deploy to production effortlessly.

* Scalability - the container-based design allows your clusters to dynamically scale up or down according to demand.


Let's take a closer look at some of these components.

==== Training

Kubeflow supports a variety of distributed training frameworks. As of the time of this writing, Kubeflow has support for:
* TensorFlow
* PyTorch
* MXNet
* Chainer
* Caffe2
* MPI

In Kubeflow, distributed training jobs are managed by application-specific controllers, known as "operators". These operators extend the Kubernetes APIs to create, manage, and manipulate the state of resources. For example, to run a distributed TensorFlow training job, the user just needs to provide a specification that describes the desired state (number of workers and parameter servers, etc), and the TensorFlow operator component will take care of the rest and manage the lifecycle of the training job.

In a later chapter we will examine how Kubeflow trains a TensorFlow model in greater detail.

==== Serving

After training your model, the next step is to serve the model in your cluster so it can handle prediction requests. Kubeflow makes it easy for data scientists to deploy machine learning models in production environments at scale. Currently Kubeflow supports TensorFlow serving and SeldonCore.


==== Hyperparameter Tuning

In machine learning, hyperparameters are variables that govern the training process. For example, what should the model's learning rate be? How many hidden layers and neurons should be in the neural network? These parameters are not part of the training data, but they can have a significant effect on the performance of the training models.

Finding the right set of hyperparameters for your training model can be a challenging task. Traditional methodologies such as grid search can be time consuming and quite tedious. 

Kubeflow provides a component (called "katib") that allows users to perform hyperparameter optimizations easily on Kubernetes clusters. Katib is inspired by Vizier, a black-box optimization framework created at Google. Users can begin with a training model that they are unsure about, define the hyperparameter search space, and Kubeflow will take care of the rest - spin up training jobs using different hyperparameters, collect the metrics, and save the results to a model database so their performance can be compared.


==== Jupyter Notebooks

Jupyter notebook is an open-source web application that allows users to create and share data, code snippets, and experiments at scale. They are popular among machine learning practitioners due to their simplicity and portability.

.A Jupyter notebook running in Kubeflow
[#1_jupyter_notebook]
image::images/1_jupyter_notebook.png[A Jupyter notebook running in Kubeflow]

In Kubeflow, you can spin up instances of Jupyter notebooks that directly interact with your cluster and its other components. For example, you can write snippets of TensorFlow distributed training code in your laptop, and bring up a training cluster with just a few clicks.

==== Pipelines

A machine learning pipeline can be seen as a graph, where each node is a stage in a workflow. Kubeflow Pipelines is a component that allows users to compose reusable workflows at ease. Its features include:
* An orchestratration engine for multi-step workflows
* An SDK to interact with pipeline components
* A user interface that allows users to visualize and track experiments, and to share results with collaborators



.A Kubeflow pipeline
[#1_kubeflow_pipeline]
image::images/1_kubeflow_pipeline.png[A Kubeflow pipeline]


=== Getting Set Up with Kubeflow

One of the great things about Kubeflow is the ability to do our initial development and exploration locally, moving into more powerful and distributed tools later on.
Deploying Kubeflow locally can be a great way to get started, and gives us access to a few debugging cheats we can use during our initial exploration.
While you can get started with Kubeflow locally, you don't have to, you can just as easily do your initial work with one of the cloud providers or on prem Kubernetes clusters covered in <<appendix_installing>>, although for all but click-to-deploy.

[TIP]
====
Probably the fastest way to get started with Kubeflow is using the simplified click-to-deploy on Google Cloud Platform (GCP). If you're in a rush to get started go ahead and jump to <<gcp_click_to_deploy>>.
====


==== Installing Kubeflow & its dependencies

Kubeflow has relatively few dependencies, most of the heavy lifting is done inside of containers which ship with their requirements.
Thankfully, Kubeflow's dependencies can be automatically installed along with the optional Minikube by running the install shell script <<mini_kube_setup_sh>>. Even if you don't plan on using Minikube this script simplifies the rest of the set up.

[[mini_kube_setup_sh]]
.Automatically install Kubeflow's dependencies & Minikube
[source, shell]
----
include::examples/dev-setup/install-kf-and-minikube.sh[tags=work]
----

[TIP]
====
If this fails to X/Y/Z, don't worry we'll cover how to fix that up in <<setting_up_minikube>>.
====



[WARNING]
====
This will modify your system packages installing and require root/super user permissions. If you wish you can instead run these commands on another host (e.g. dedicated KF development enviroment).
====

If you don't want to install Minikube, you can manually install Kubeflow's dependencies: ksonnet and kubectl. Even if you have these installed, you will want to check that you have the right versions installed for your version of Kubeflow.
// TODO(holden): Where? Release notes?
Ksonnet is on github, with its release posted at link:$$https://github.com/ksonnet/ksonnet/releases$$[https://github.com/ksonnet/ksonnet/releases], and you can install it with <<install_ksonnet_sh>>.

[[install_ksonnet_sh]]
.Install ksonnet
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=ksonnet]
----



Kubectl is more widely packaged, with the different installation options covered in the link:$$https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl$$[kubernetes documentation https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl]. Ubuntu (snap) <<install_kubectl_snap>> and Homebrew users can install Kubectl <install_kubectl_homebrew>> the simplest with package manager, with others covered in the guide.
Kubectl can also be installed outside of your package manager <<install_kubectl_curl>>, although this requires manual updating.

[[install_kubectl_snap]]
.Install kubectl with snap
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=ubuntu-kubectl]
----

[[install_kubectl_homebrew]]
.Install kubectl with homebrew
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=osx-kubectl]
----

[[install_kubectl_curl]]
.Install kubectl without a package manager
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=no-pkg-manager-kubectl]
----




Once you have the dependencies installed, you can now install Kubeflow with <<install_kf_sh>>, and optionally add it to your path.

[[install_kf]]
.Install Kubeflow
[source, shell]
----
include::examples/dev-setup/install-kf.sh[tags=no-pkg-manager-install]
----

You now have Kubeflow installed! There are some additional optional tools you can set up to make the rest of this book easier we will cover next.

[[setting_up_minikube]]
==== Finishing setting up Kubeflow on Minikube (optional)

The Kubeflow project has a link:$$https://www.kubeflow.org/docs/started/getting-started-minikube/$$[frequently updated guide on how to install Kubeflow with Minikube at https://www.kubeflow.org/docs/started/getting-started-minikube/].
You don't need to have a local Kubernetes cluster, but many data scientists and developers find having a local cluster to test with (be it Minikube or other).
// TODO: other local k8s options



==== Setting up your Kubeflow development enviroment

In addition to the core dependencies you may find some additional tools useful.
Much of Kubernets and Kubeflow is configured with
either link:$$https://yaml.org/$$[YAML Ain't Markup Language (YAML)]
or link:$$https://ksonnet.io/$$[ksonnet] (which is an extension of link:$$https://jsonnet.org/$$[Jsonnet]).

[TIP]
====
This part is optional, if it ends up being frustrating or slowing you down feel free to skip ahead.
====


Inside of the Kubeflow project, the Jsonnet library is used to automatically format Ksonnet into a standard layout. This autoformatter can also catch syntax errors or other simple errors earlier on in the deploy. The jsonnet package link:$$https://github.com/google/jsonnet/releases$$[releases are available on GitHub] <<jsonnet_manual>>, link:$$https://snapcraft.io/$$[Snap] <<jsonnet_snap>> (from Canonical). It is also listed on PyPi, but currently does not install the command line tools. Some of the IDE tools for Jsonnet depend on the command line binary.

[[jsonnet_snap]]
.Install jsonnet with snap (Ubuntu)
====
[source, shell]
----
include::examples/dev-setup/jsonnet.sh[tags=snap]
----
====

[[jsonnet_manual]]
.Install jsonnet manually (everyone else)
====
[source, shell]
----
include::examples/dev-setup/jsonnet.sh[tags=manual]
----
====


Most Integrated Development Enviroments (IDEs) offer some sort of tooling for editing YAML and Jsonnet, but you may have to install these seperately.
For InteliJ //TODO(trevor)
For emacs there are many modes available for YAML editing, as well as the link:$$jsonnet-mode$$[jsonnet] (which is installable from link:$https://melpa.org/$$[Milkypostman’s Emacs Lisp Package Archive (MELPA)]).
Atom has syntax highlighting available as packages for both link:$$https://atom.io/packages/language-yaml$$[YAML] and link:$$https://atom.io/packages/language-jsonnet$$[Jsonnet].
If you use a different IDE don't throw it away just for better ksonnet editing before you explore the plugin available.






[TIP]
====
If you get stuck here, or if your permissions/policies don't allow you to use minikube, just jump on over to <<appendix_installing>> and you can deploy your Kubeflow app's against your remote K8s cluster. 
====


=== Getting Help / Community Resources

We are so glad you've decided to use this book to start your adventures into Kubeflow.
However, like all adventures, there may come a point when your guide book isn't enough to carry you through.
Thankfully there are a collection of community resources where you can interact with others on similar adventures to your own.
We encourage you to sign up for the link:$$http://kubeflow.slack.com$$[Kubeflow slack at http://kubeflow.slack.com], one of the more active areas of discussion, now since account approval is semi-manual.
The link:$$https://www.kubeflow.org/$$[kubeflow project page is at https://www.kubeflow.org/].

[TIP]
====
If you want to quickly explore Kubeflow end-to-end there are some link:$$https://codelabs.developers.google.com/$$[Google codelabs] with Kubeflow as well.
====

=== Conclusion

At this point you have everything you need to get started on your Kubeflow adventure: a Kubernetes cluster, Kubeflow and its core dependencies, and a desire to have fun.
In the next chapter <<simple_training_ch>>, we'll train and serve a relatively simple machine learning model together to give you an idea of how the basics of how to use Kubeflow.
