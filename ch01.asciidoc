[[who_is_kubeflow_for_ch]]
== What does Kubeflow solve & who’s it for, and how to get started


Kubeflow solves the problem of needing to build portable, reliable, scalable machine learning pipelines and exposing the results.
We hope Kubeflow is the right tool for you, and briefly look at some alternatives in <<alternatives_to_kubeflow>>, but even if it is not learning about Kubeflow can help provide a good mental model of how to build production machine learning workflows.

[TIP]
====
Despite common misconception, Kubeflow is more than just Kubernetes and tensorflow -- you can use it for all sorts of machine learning models.
====

[WARNING]
====
Kubeflow is rapidly evolving, this book is written for $KUBEFLOW_VERSION, if you are using a newer version of Kubeflow you will want to pay close attention to the release notes for things which may have changed.
====



=== Who is Kubeflow for?

Kubeflow is for both data scientist and data engineers looking to build production machine learning pipelines.
Kubeflow packages components for all the different stages of a models life (data exploration, feature prep, model training, model serving, and model testing); allowing you
to build integrated end-to-end pipelines.
These tools can be run either locally for your development or on a production cluster once you are ready.
Many of benefits of using Kubeflow come from a unified systems, containerization and running on Kubernetes.


Containerization means no more "it worked on my machine" or "just install extra_pip_requirements.txt".
Data Scientist with Python experience can think of containers as a like heavy duty virtual environment, which includes the operating system to the packages and everything in between.
This is used to isolate your from the host environment (or machine running the container).
The isolation means that all dependencies must be explicitly added and you won't accidently start depending on some system packages.
Containirizing our machine learning makes it portable and reproducible.


[TIP]
====
Docker containers are made out of multiple layers and are easily compossible, so, if for example, there is a container image that has most of what you need (CUDA, etc.) but you also need some extra packages on top of it, you can build a container using another one as the base.
====




Kubernetes allows our pipelines to be scalable without sacrificing portability, allowing us to avoid becoming locked into a specific cloud provider.
With Kubernetes the different stages of your pipeline can request the different resources they need from a cluster, and different versions of your pipeline can run with different resources.


Now one can of course build their own containirzed machine learning pipelines on Kubernetes without using Kubefklow, but Kubeflow aims to make this substantailly easier.
Kubeflow provides an easier partially-standarized interface to the tools you would be likely to use on your own adventure, as well making it easier to configure your pipeline to use cloud accelerations like TPUs (tensor processing units).


[TIP]
====
We talk about who this book is for in <<assumptions_about the_audience>> as well as the required background and resources to get up to speed if you need them.
====


[[alternatives_to_kubeflow]]
=== Brief Alternatives to Kubeflow

[[breif_kubeflow_design_and_core_components]]
=== Kubeflow’s Design & Core Components

In the machine learning landscape, there are many diverse tool sets and frameworks. Kubeflow does not seek to reinvent the wheel or provide a "one size fits all" solution - instead, it allows machine learning practitioners to compose and customize their own stacks based on specific needs. It is designed to simplify the process of building and deploying machine learning at scale; allowing data scientists to do their jobs without worrying about the "boring parts" of building the infrastructure.

Kubeflow seeks to tackle the problem of simplifying machine learning through three aspects: composability, portability, and scalability.

* Composability - the core components come from data science tools that are already familiar to machine learning practictioners. They can be used independently to facilitate specific stages of machine learning, or composed together to form end-to-end pipelines.

* Portability - taking advantage of Kubernetes and cloud-native microservices, Kubeflow does not require you to anchor to any particular platform. You can develop and prototype on your laptop, and deploy to production effortlessly.

* Scalability - the container-based design allows your clusters to dynamically scale up or down according to demand.


Let's take a closer look at some of these components.

==== Training

Kubeflow supports a variety of distributed training frameworks. As of the time of this writing, Kubeflow has support for:

* TensorFlow
* PyTorch
* MXNet
* Chainer
* Caffe2
* MPI


In Kubeflow, distributed training jobs are managed by application-specific controllers, known as "operators". These operators extend the Kubernetes APIs to create, manage, and manipulate the state of resources. For example, to run a distributed TensorFlow training job, the user just needs to provide a specification that describes the desired state (number of workers and parameter servers, etc), and the TensorFlow operator component will take care of the rest and manage the lifecycle of the training job.

In a later chapter we will examine how Kubeflow trains a TensorFlow model in greater detail.

==== Serving

After training your model, the next step is to serve the model in your cluster so it can handle prediction requests. Kubeflow makes it easy for data scientists to deploy machine learning models in production environments at scale. Currently Kubeflow supports TensorFlow Serving and SeldonCore.

Serving a model on Kubeflow is fairly straightforward. There is no need to build or customize a container yourself - simply point Kubeflow to where your model is stored, and a server will be ready within seconds to service requests.

==== Hyperparameter Tuning

In machine learning, hyperparameters are variables that govern the training process. For example, what should the model's learning rate be? How many hidden layers and neurons should be in the neural network? These parameters are not part of the training data, but they can have a significant effect on the performance of the training models.

Finding the right set of hyperparameters for your training model can be a challenging task. Traditional methodologies such as grid search can be time-consuming and quite tedious.

Kubeflow provides a component (called "Katib") that allows users to perform hyperparameter optimizations easily on Kubernetes clusters. Katib is inspired by Vizier, a black-box optimization framework created at Google. It leverages advanced searching algorithms such as Bayesian optimization to find optimal hyperparameter configurations.

With Kubeflow, users can begin with a training model that they are unsure about, define the hyperparameter search space, and Kubeflow will take care of the rest - spin up training jobs using different hyperparameters, collect the metrics, and save the results to a model database so their performance can be compared.


==== Jupyter Notebooks

Jupyter notebook is an open-source web application that allows users to create and share data, code snippets, and experiments at scale. They are popular among machine learning practitioners due to their simplicity and portability.

.A Jupyter notebook running in Kubeflow
[#1_jupyter_notebook]
image::images/1_jupyter_notebook.png[A Jupyter notebook running in Kubeflow]

In Kubeflow, you can spin up instances of Jupyter notebooks that directly interact with your cluster and its other components. For example, you can write snippets of TensorFlow distributed training code in your laptop, and bring up a training cluster with just a few clicks.

==== Pipelines

A machine learning pipeline can be seen as a graph, where each node is a stage in a workflow. Kubeflow Pipelines is a component that allows users to compose reusable workflows at ease. Its features include:

* An orchestratration engine for multi-step workflows

* An SDK to interact with pipeline components

* A user interface that allows users to visualize and track experiments, and to share results with collaborators


.A Kubeflow pipeline
[#1_kubeflow_pipeline]
image::images/1_kubeflow_pipeline.png[A Kubeflow pipeline]

Each building block in a pipeline is a self-contained step in a machine learning workflow, such as preprocessing, transformation, training, or cross-validation. In Kubeflow, each of these blocks is built as a Docker image. This allows users to share and reuse individual components with ease.

=== Getting Set Up with Kubeflow

One of the great things about Kubeflow is the ability to do our initial development and exploration locally, moving into more powerful and distributed tools later on.
Deploying Kubeflow locally can be a great way to get started, and gives us access to a few debugging cheats we can use during our initial exploration.
While you can get started with Kubeflow locally, you don't have to, you can just as easily do your initial work with one of the cloud providers or on prem Kubernetes clusters covered in <<appendix_installing>>, although for all but click-to-deploy we thing starting locally will be the fastest.

[TIP]
====
The fastest way to get started with Kubeflow is using the simplified click-to-deploy app on Google Cloud Platform (GCP). If you're in a rush to get started go ahead and jump to <<gcp_click_to_deploy>>.
====


==== Installing Kubeflow & its dependencies

Kubeflow has relatively few system dependencies, most of the heavy lifting is done inside of containers which include their requirements.
The biggest requirement for Kubeflow is access to a Kubernetes cluster, be it local or remote.
Kubeflow ships with scripts to automate the set up of the system dependencies as well as a local Kubernetes cluster, called Minikube.
You don't need to install Kubeflow with these scripts, but the automatic setup tools can help you get up and running faster even if you don't plan on using Minikube.



===== Automatically

Kubeflow's system dependencies can be automatically installed along with the optional Minikube by running the install shell script <<mini_kube_setup_sh>>.
If you prefer MicroK8s, Canonical Labs has their own auto-install script covered in <<setting_up_microk8s>>.

[[mini_kube_setup_sh]]
.Automatically install Kubeflow's dependencies & Minikube
====
[source, shell]
----
include::examples/dev-setup/install-kf-and-minikube.sh[tags=work]
----
====

[TIP]
====
If this fails to install minikube, don't worry we'll cover how to fix that up in <<setting_up_minikube>>.
====



[WARNING]
====
This will modify your system packages installing and require root/super user permissions. If you wish you can instead run these commands on another host (e.g. dedicated KF development enviroment).
====

===== Manually

// TODO(holden): This is going to change

If you don't want to install Minikube, you can manually install Kubeflow's dependencies: ksonnet and kubectl. Even if you have these installed, you will want to check that you have the right versions installed for your version of Kubeflow.
// TODO(holden): Where? Release notes?
Ksonnet is on github, with its release posted at link:$$https://github.com/ksonnet/ksonnet/releases$$[https://github.com/ksonnet/ksonnet/releases], and you can install it with <<<install_ksonnet_sh>>.

[[install_ksonnet_sh]]
.Install ksonnet
====
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=ksonnet]
----
====



Kubectl is more widely packaged, with the different installation options covered in the link:$$https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl$$[kubernetes documentation https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl]. Ubuntu (snap) <<install_kubectl_snap>> and Homebrew users can install Kubectl <install_kubectl_homebrew>> the simplest with package manager, with others covered in the guide.
Kubectl can also be installed outside of your package manager <<install_kubectl_curl>>, although this requires manual updating.

[[install_kubectl_snap]]
.Install kubectl with snap
====
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=ubuntu-kubectl]
----
====

[[install_kubectl_homebrew]]
.Install kubectl with homebrew
====
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=osx-kubectl]
----
====

[[install_kubectl_curl]]
.Install kubectl without a package manager
====
[source, shell]
----
include::examples/dev-setup/install-ksonnet-and-kubectl.sh[tags=no-pkg-manager-kubectl]
----
====



Once you have the dependencies installed, you can now install Kubeflow with <<install_kf_sh>>, and optionally add it to your path.

[[install_kf]]
.Install Kubeflow
====
[source, shell]
----
include::examples/dev-setup/install-kf.sh[tags=no-pkg-manager-install]
----
====


You now have Kubeflow installed on your machine. There are some additional optional tools you can set up to make the rest of this book easier we will cover next.


==== Setting up Kubeflow for local use

Being able to have the same software running locally as in production is one of the great advantages of Kubeflow.
To support this you will need a local version of Kubernetes installed.
Kubeflow has setup scripts which automatically download and attempt to set up Minikube, but this is not your only option.
Ubuntu users in particular may find MicroK8s faster to set up.

[TIP]
====
You don't need to have a local Kubernetes cluster, but many data scientists and developers find having a local cluster to test with (be it Minikube or MicroK8s or other).
====

[[setting_up_minikube]]
===== Minikube

Minikube is a local version of Kubernetes which can be used in conjunction with Kubeflow.

The set up script for Kubeflow we showed earlier will attempt to install Minikube so you can work locally, although it may sometimes not succeed.
// TODO: other local k8s options



The most common reason for the automatic set up of Minikube as part of the set-up scripts failing is missing a hypervisor or Docker install.
The regardless of your OS you should be able to use link:$$https://www.virtualbox.org/wiki/Downloads$$[VirtualBox], however other options like KVM on Linux, Hyper-V on Windows, and HyperKit on MacOs all work as well.
There are installation guides for Minikube on the main Kubernetes website link:$$https://kubernetes.io/docs/tasks/tools/install-minikube/$$[] as well as the Kubeflow specific one at link:$$https://www.kubeflow.org/docs/started/getting-started-minikube/$$[].



[TIP]
====
The Kubeflow project has a link:$$https://www.kubeflow.org/docs/started/getting-started-minikube/$$[frequently updated guide on how to install Kubeflow with Minikube at https://www.kubeflow.org/docs/started/getting-started-minikube/].
====

[[setting_up_microk8s]]
===== MicroK8s

link:$$https://microk8s.io/$$[MicroK8s] is another single node Kubernetes option.
Ubuntu users can directly install MicroK8s from snap with <<install_microk8s>>.

[[install_microk8s]]
.Install MicroK8s
====
[source, shell]
----
include::examples/dev-setup/install-microk8s.sh[tags=installmicrok8s]
----
====

Once you have MicroK8s installed you can use the Canonical provided bootstrap scripts to set up Kubeflow on top of it <<bootstrap_microk8s_kf>>,
or use it like a regular K8s cluster.

.Bootstrap Kubeflow on MicroK8s
[[bootstrap_microk8s_kf]]
====
[source, shell]
----
include::examples/dev-setup/install-microk8s.sh[tags=bootstrapwithcanonicallabs]
----
====



==== Setting up your Kubeflow development enviroment

In addition to the core dependencies you may find some additional tools useful.
Much of Kubernets and Kubeflow is configured with
either link:$$https://yaml.org/$$[YAML Ain't Markup Language (YAML)]
or link:$$https://ksonnet.io/$$[ksonnet] (which is an extension of link:$$https://jsonnet.org/$$[Jsonnet]).

[TIP]
====
This part is optional, if it ends up being frustrating or slowing you down feel free to skip ahead.
====


Inside of the Kubeflow project, the Jsonnet library is used to automatically format Ksonnet into a standard layout. This autoformatter can also catch syntax errors or other simple errors earlier on in the deploy. The jsonnet package link:$$https://github.com/google/jsonnet/releases$$[releases are available on GitHub] <<jsonnet_manual>>, link:$$https://snapcraft.io/$$[Snap] <<jsonnet_snap>> (from Canonical). It is also listed on PyPi, but currently does not install the command line tools. Some of the IDE tools for Jsonnet depend on the command line binary.

[[jsonnet_snap]]
.Install jsonnet with snap (Ubuntu)
====
[source, shell]
----
include::examples/dev-setup/jsonnet.sh[tags=snap]
----
====

[[jsonnet_manual]]
.Install jsonnet manually (everyone else)
====
[source, shell]
----
include::examples/dev-setup/jsonnet.sh[tags=manual]
----
====


Most Integrated Development Enviroments (IDEs) offer some sort of tooling for editing YAML and Jsonnet, but you may have to install these seperately.
For InteliJ //TODO(trevor)
For emacs there are many modes available for YAML editing, as well as the link:$$jsonnet-mode$$[jsonnet] (which is installable from link:$$https://melpa.org/$$[Milkypostman’s Emacs Lisp Package Archive (MELPA)]).
Atom has syntax highlighting available as packages for both link:$$https://atom.io/packages/language-yaml$$[YAML] and link:$$https://atom.io/packages/language-jsonnet$$[Jsonnet].
If you use a different IDE don't throw it away just for better ksonnet editing before you explore the plugin available.

[TIP]
====
If you get stuck here, or if your permissions/policies don't allow you to use minikube, just jump on over to <<appendix_installing>> and you can deploy your Kubeflow app's against your remote K8s cluster.
====

[[brief_alternatives_to_kubeflow]]
=== Brief Alternatives to Kubeflow

Within the research community, various alternatives exist that provide uniquely different functionality to that of Kubeflow.
In recent research cadences, model development or training has received much attention and support with regards to advancements in infrastructure, theory, and systems.
Prediction serving, on the other hand, has received relatively less attention.
As such, it is commonly seen that data science practitioners end up hacking together an amalgam of critical systems components that are integrated to support serving and inference across various workloads and continuously evolving frameworks.
However, given the demand for constant availability and horizontal scalability, solutions like Kubeflow and various others are gaining traction through industry as powerful architectural abstraction tools and as convincing research scopes.

==== Clipper (RiseLabs)

[#6_clipper]
image::images/6_clipper.png[Clipper and its modular architecture]
One interesting alternative to Kubeflow, is a general-purpose low-latency prediction serving system that came out of RiseLabs, titled Clipper. In an attempt to simplify deployment, optimization, and inference, Clipper has developed a layered architecture system like the one seen above.
Through various optimizations and its modular design, Clipper, in its seminal paper, has achieved low latency and high throughput predictions at comparable levels to TensorFlow Serving, on three TensorFlow models of varying inference costs.

Clipper is divided across two abstractions, aptly named: model selection and model abstraction layers.

The model selection layer is quite sophisticated in that it uses an adaptive online model selection policy and various ensemble techniques to incorporate feedback and automatically select and combine predictions
from models that can span multiple machine learning frameworks. Since you are continuously learning from feedback throughout the lifetime of your application, the model selection layer self-calibrates failed model without needing to interact directly with the policy layer.
The two different selection policies that are implemented allow for single-model selection, using a multi-armed bandit algorithm, and ensemble-model selection, using bootstrap aggregation (or bagging).

The model abstraction layer provides an implementable interface for providing pluggability in terms of custom machine learning frameworks.
The layer is comprised of a prediction cache, an adaptive query-batching component, and model containers that are communicable through RPC.
These model containers are built as Docker containers, so it was intended that Clipper may run on Kubernetes seamlessly.

Clipper's modular architecture and focus on containerization, similar to Kubeflow, enables caching and batching mechanisms to be shared across frameworks while also reaping the gains of scalability, concurrency, and flexibility in adding new model frameworks

Graduating from just scientific theory into a functional end-to-end system, Clipper has gained traction within the scientific community and has had various parts of its architectural designs incorporated into recently introduced machine learning systems; nonetheless, we have yet to see if it will be adopted in industry at scale.

==== MLflow (Databricks)

MLflow is Databrick's own flavor of open-source machine learning development.
The architecture of MLflow leverages a lot of the same architectural paradigms of Clipper, including its framework agnostic nature,  while focusing on three major components that it calls: Tracking, Projects, and Models.

MLflow Tracking functions as an API with a complementing UI for logging parameters, code versions, metrics and output files. This is quite power in machine learning as tracking parameters, metrics, and artifacts is of paramount importance.
The power of this API is that it can be leveraged in a standalone or notebook setting.

MLflow Projects provides a standard format for packaging reusable data science code, defined by a yaml file that can leverage source-controlled code and dependency management via Anaconda.
The project format makes it easy to share reproducible data science code, as reproduciblity is critical for machine learning practitioners.

MLflow Models is a convention for packaging machine learning models in multiple format.
Each MLflow Model is saved as a directory containing arbitrary files and an MLmodel descriptor file.

MLflow is still in active development, but with the entire project being open-sourced, the visibility and community excitement around its development is enticing as well.

==== Others

Because of the challenges presented in machine learning development, many organizations have started to build internal machine learning platforms to manage their machine learning lifecycle.
For example: Bloomberg, Facebook, Google, Uber have built the Data Science Platform, FBLearner Flow, TFX, and Michelangelo to manage data preparation, model training and deployment.
With the machine learning infrastructure landscape always evolving and maturing, we are excited to see how open-source projects, like Kubeflow, will bring much-needed simplicity and abstraction to machine learning development.

=== Getting Help / Community Resources

We are so glad you've decided to use this book to start your adventures into Kubeflow.
However, like all adventures, there may come a point when your guide book isn't enough to carry you through.
Thankfully there are a collection of community resources where you can interact with others on similar adventures to your own.
We encourage you to sign up for the link:$$http://kubeflow.slack.com$$[Kubeflow slack at http://kubeflow.slack.com], one of the more active areas of discussion, now since account approval is semi-manual.
// TODO(holden): Check and see if we split the user/dev list out from discuss@
While less active than slack, their is also a mailing list at link:$$https://groups.google.com/forum/#!forum/kubeflow-discuss$$[].
The link:$$https://www.kubeflow.org/$$[kubeflow project page is at https://www.kubeflow.org/].

[TIP]
====
If you want to quickly explore Kubeflow end-to-end there are some link:$$https://codelabs.developers.google.com/$$[Google codelabs] with Kubeflow as well.
====

=== Conclusion

At this point you have everything you need to get started on your Kubeflow adventure: a Kubernetes cluster, Kubeflow and its core dependencies, and a desire to have fun.
In the next chapter <<simple_training_ch>>, we'll train and serve a relatively simple machine learning model together to give you an idea of how the basics of how to use Kubeflow.
