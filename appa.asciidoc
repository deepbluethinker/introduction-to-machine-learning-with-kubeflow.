[[appendix]]
[appendix_installing]
== Setting Kubeflow up on your provider(s) of choice

While you can do much of your development locally on minikube, once you're ready to start training and predicting real production workloads you'll want to go beyond what can be accomplished on a single machine. This doesn't mean you _shouldn't_ set up minikube, it's an amazing resource for developing and testing locally.

If you don't have a Kubernetes cluster set up in your cloud simply jump to the provider(s) of your choice bellow and see how to set up a Kubeflow cluster. If you're in a multi-cloud deployment, don't fret we can set up Kubeflow to run on multiple clouds by configuring different environments.

[TIP]
====
While you don't need to deploy Kubeflow to it's own cluster, while you are in the process of learning we recommend having a separate cluster you can experiment with.
====


[[gcp_install]]
=== Google Cloud Platform (GCP) w/ Google Kubernetes Engine (GKE)

Kubeflow can be easily deployed on Google Cloud Platform (GCP), using the Google Kubernetes Engine (GKE) & storage Google Cloud Storage (GCS). Other tools like Dataflow can be used, although doing so will reduce the portability of your Kubeflow pipelines so we will call out any such instances along with portable alternatives. Specialized resources, like Tensor-Processing-Units (TPUs) can also be accessed, and while not available on other providers do not reduce portability since they primarily accelerate your standard workflow.


There are two primary ways to get started with Kubeflow on, one is the standard command line tools, and an even easier link:$$https://deploy.kubeflow.cloud/$$[$"click-to-deploy"] system.
// TODO(holden): Verify is this the recommendation we want to give? It's the one I want -- I don't trust GUIs
Click-to-deploy is recommended for users on locked down corporate machines, tutorials, and getting started. For longer term and portable deployments the authors have found the traditional command line tools give them more flexibility and reduced dependence on magic.

// TODO(holden): Put a tip similar to this around the point of setting up Minikube incase folks get frustrated at that point

[TIP]
====
You can use click-to-deploy even if you don't have Kubernetes installed locally, which means it can often be even faster than starting with minikube (although, long term, we do recommend having a local deployment you can debug, as discussed in <<debugging>>).
====



Regardless of which deployment you go with you will want a GCP project to deploy Kubeflow into. This does not need to be a separate project, however there are benefits to isolating your exploration work from your regular work. If you decide to create a separate project, the current steps are described at link:$$https://cloud.google.com/resource-manager/docs/creating-managing-projects$$.

[TIP]
====
Pick a project name which is easy to type and doesn't require shell escaping, you will thank yourself later.
====



[[gcp_click_to_deploy]]
==== Click To Deploy

Click-to-deploy is by far the fastest way to get started with Kubeflow in the cloud.
The click to deploy web UI is located at link:$$https://deploy.kubeflow.cloud/$$ and allows you to deploy Kubeflow entirely from your web browser, as shown in <<1_click_to_deploy_root>>.
However it does have limitations which can make it more challenging to work with if, especially you have a local
development environment or tools you feel more comfortable with.


.Home page of the click to deploy service
[#1_click_to_deploy_root]
image::images/1_click_to_deploy_root.png[Home page of the click to deploy service]


[TIP]
====
Click-to-deploy will create a new Kubernetes cluster matching the name you provide for the deployment during setup.
====

[WARNING]
====
Click-to-deploy Kubeflow attempts to enable some services on GCP which require billing to be enabled. This does not necessarily mean a credit card has to be on file, e.g. educational accounts _may_ work, but purely free accounts are unlikely to work. If you get the error "" shown in <<3_iap_no_billing_failure>> then you will need to enable billing or do manual setup.
====

.Attempt to click-to-deploy Kubeflow into a project without billing set up
[#3_iap_no_billing_failure]
image::images/3b_iap_no_billing_failure.png["Click to deploy billing failure with error message Deployment Error programmerboo@gmail.com: Error trying to enable this required service: container.googleapis.com. Error: Errors enabling service: Operation does not satisfy the following requirements: billing-enabled {Billing must be enabled for activation of service '' in project 'kf-click-to-delpoy-no-iap' to proceed., link:$$https://console.developers.google.com/project/kf-click-to-delpoy-no-iap/settings$$}"]


Click-to-deploy has two different access modes available, identity aware proxy (IAP) and non-AIP modes. In IAP mode, click-to-deploy creates a gateway you can use to access your cluster with oauth, and in non-IAP mode you access your cluster through cloud shell or other means footnote:[Personally I often use a jump host along with sshuttle, but it is a matter of personal preference.]. If you are in a hurry to get started you may find that skipping IAP deployment mode makes it easier to get started. If you find your self wanting IAP access later on, you can always deploy the IAP component to your cluster at a later date.


Regardless of the deployment method you chose, you start the process at link:$$https://deploy.kubeflow.cloud/$$.


[[google_click_to_deploy_cloudshell]]
===== No identity aware proxy (IAP) mode (simplest)


If you choose to skip IAP mode you can be up and running inside the matter of minutes. Navigate your browser to the click to deploy service at link:$$https://deploy.kubeflow.cloud/$$ and select the account you wish to use, and selecting "Skip IAP" <<1_click_to_deploy_root>>.


From there you just press "Create Deployment" and grab a cup of coffee/tea/La Croix or Bud light lime.


Once your deployment has succeeded you should see the message "Status of kubeflow: RUNNING" at the bottom of the deployment console as in <<4_noiap_success>>


.Successful click to deploy without a proxy
[#4_noiap_success]
image::images/4_noiap_success.png["Successful click-to-deploy without IAP"]

//TODO(holden): Footnote or link jumphost?
Once you have your Kubeflow cluster up and running you can go ahead and connect by clicking on the "Cloud shell" button in <<4_noiap_success>>.

[WARNING]
====
If you use multiple google accounts, click-to-deploy assumes that the account you are using Google cloud with is also the first Google account (in priority order) as signed in on your browser (.e.g it is `/u/0`). This is a known issue and is tracked in link:$$https://github.com/kubeflow/kubeflow/issues/2267$$.
====

If the automatic launching of cloud-shell did not work for you, you can run the command <<cloudshell_connect_to_project>>. If you launched your Kubeflow cluster with IAP enabled hhowever, the repo will not exist.

[[cloudshell_connect_to_project]]
.Command to run in cloudshell to connect to a click-to-deploy Kubeflow cluster
[source, shell]
----
include::examples/gcp-setup/cloudshell_script.sh[tags=cloudshell_script]
----

If later on you find your self wishing you had a proxy to simplify access, you can check out the section on setting up IAP <<setup_iap>>.

Congratulations, you now have Kubeflow deployed!

[WARNING]
====
As awesome and amazing as cloudshell can be for getting started, it does not persist items outside of your home directory, so system packages installed may disappear between access.
====


[[gogole_click_to_deploy_iap]]
===== Identity Aware Proxy Mode

Using click-to-deploy to set up Kubeflow with identity aware proxy mode will allow you to skip having to interact with Google Cloud shell and directly access the Kubeflow UI using your Google credentials. However, doing so may be challenging, especially for accounts without custom domains configured which involve configuring restricted scope.


[WARNING]
====
IAP access can take some time to set up, the guide says "20 minutes", if it takes longer you may need to double check your oauth tokens and possibly submit them for verification if they access restricted scopes.
====

[TIP]
====
If you use cloudshell through the Google Cloud console, you will want to enable link:$$https://cloud.google.com/shell/docs/features#boost_mode$$[boost mode] to provide sufficient resources.
====




[[gcp_cli_deploy]]
==== Command line Deployment

The command line deployment of Kubeflow on Google cloud is fairly simple. If you already have a Google Kubernetes Engine (GKE) cluster up and running you, and local SDK tools installed, can skip ahead to <<using_gke_cluster>>.

[[set_up_gke_cluster_cli]]
===== Setting up your GKE cluster
You will need to enable Google's Kubernetes Engine (GKE) in your account, if you have not already done so before, which you can do by visiting link:$$https://console.cloud.google.com/kubernetes$$.


After you have GKE enabled you will want to install the command line Google cloud tools so you can create, modify, and delete your clusters from the command line. Many users can install the "Google Cloud SDK" package or some variant from their package manager <<install-gcloud-ubuntu>>.
However if you don't have sudo permissions or want a different version installed you can install gcloud using the installation script at <<install-gcloud-general>>.

[[install-gcloud-ubuntu]]
.Install gcloud SDK on Ubuntu/Debian
====
[source, shell]
----
include::examples/gcp/setup-gcp.sh[tags=ubuntu]
----
====

[[install-gcloud-general]]
.Install gcloud SDK in general without sudo
====
[source, shell]
----
include::examples/gcp/setup-gcp.sh[tags=general]
----
====

Once you have the Google Cloud SDK installed you will want to go ahead and create your cluster. For initial explorations you will only need a small cluster, and we can use either dynamic scaling or make a larger cluster later on.

//TODO(holden): Include tip with error message for not enabled GKE



[[using_your_gke_cluster]]
===== Using your GKE cluster with Kubeflow

While you can use your GKE cluster like any generic Kubernetes cluster, there are some extra bits of magic to simplify your life available. To be able to use Kubeflow on your machine you going to need to install the Kubeflow dependencies mentioned in <<setting_up_kubeflow_dependencies>>.



[[ibm_install]]
=== IBM Cloud (Bluemix) w/IBM Cloud Kubernetes Service

:imagesdir: ibm-install-guide/assets/images

[.lead]

In this module we're going to walk through installing Kubeflow on IBM Bluemix.  While this is very
similar to installing Kubeflow on other cloud providers, there are some tricks and gotchyas specific
to Bluemix we want the reader to be aware of.


===== In this guide we are going to

* Create a Kubernetes Cluster on IBM Bluemix
* Create a Bucket in IBM Object Store and enable the S3 interface
* Install Kubeflow
* Train a simple Tensorflow model (MNIST)
* Create a serving layer for the model to predict new hand written digits


IMPORTANT: We presume the user has already signed up for an IBMCloud account, has installed the CLI tools, and has logged in
at the command line. Please go to https://console.bluemix.net/docs/cli/index.html#overview for more info on installing
the CLI tools.

==== Creating a Kubernetes Cluster in IBM Cloud

For this entire tutorial, there is an "easy" way which will get Kubeflow up and running on IBMCloud with minimal effort
and understanding, and a "long way" that explains what the scripts are doing, and hopefully will be instructive in
helping the user understand what, how, and why the script is doing the things that it is doing. The user is encouraged to
use the easy way for assistance but to read through and understand the instructive way as needed.

===== Easy Way

The easy way is to clone the tutorial repo, login to IBMCloud, and run the `create-k8s-cluster.sh` script. This can be
acheived in the following three lines of code (though login is interactive and may be slightly different depending on
the security on your account).

```bash
ibmcloud login
git clone https://github.com/intro-to-ml-with-kubeflow/ibm-install-guide
cd ;ibm-install-guide/create-k8s-cluster.sh
```

That will fire off a series of commands that will setup a small Kubernetes cluster on IBMCloud.  It takes about ten
minutes to set up a cluster, so now let's go through all of the lines in the script and see what it is doing.


===== Instructive Way

The first thing to do when setting up your Kubernetes cluster will be to name it.  This can be anything. The default name
for this tutorial is `kubeflow-tutorial`.  Next you will select a *zone* in which to create your cluster.  You can see a
full list of available zones with the command `ibmcloud ks zones`.  The script simply chooses the last zone in the list.
Next we will set the version of Kubernetes we want to run.  We have chosen `1.10.11` as it is the latest stable version
available on IBMCloud at the time of writing. Next you will need to choose  your machine types.  To see a full list of
available machines you can run `ibmcloud ks machine-types $ZONE` (replace `$ZONE` with your zone).  For the tutorial however,
we are going to use the smallest cheapest machines `u2c.2x4`.

include::ibm-install-guide/create-k8s-cluster.sh[tag=setClusterName]
include::ibm-install-guide/create-k8s-cluster.sh[tag=setZoneAndV]
include::ibm-install-guide/create-k8s-cluster.sh[tag=setMachineType]

Next you may need to create new VLANs.  If you have already set up a Kubernetes cluster in this zone however, you won't
need to create them.  To find out if VLANs exist in the zone run `ibmcloud ks vlans $ZONE`. If that command returns an
empty list, then you can create the cluster (and the VLANs automatically), with the following command:

include::ibm-install-guide/create-k8s-cluster.sh[tag=createClusterAndVLANS]

WARNING: If you already have VLANs the previous command will throw an error- please use following command instead.

If you already have VLANs you will need to explicitly set the public and private VLAN by their ID.  The shell script
looks at the output of `ibmcloud ks vlans $ZONE` and parses out the first *public* and *private* VLAN's ID.  You could
easily do this by just writing down the ID of a VLAN you wish to explicitly use.

include::ibm-install-guide/create-k8s-cluster.sh[tag=createClusterInVLAN]



==== Creating a Bucket in IBM Object Store

To create an S3 bucket using the Bluemix Web GUI, first log into IBM Cloud.  You will initially be brought to the
Dashboard.  In this section, we are going to provision a Cloud Object storage instance and setup a bucket with S3 interface.
If you already have a Cloud Object Storage instance you wish to use, please skip ahead to step *step number*.

===== Provisioning Cloud Object Storage

When you login you should be at the Dashboard.  The first step is to click on the Catalog tab at the top of the screen.

.Click on 'Catalog', circled in Red
[#img-dash]
[caption="Step 1: "]
image::dash.png[Dash,600,200]

In the next screen, search for 'Object Storage', you should see the following icon come up- click that.

.Search for Object Storage
[#img-dash]
[caption="Step 2: "]
image::obj-sto.png[Dash,600,200]

In the next screen, feel free to name your service something fun or to use the name generated by the system. Click 'Create'
when you're done (in the bottom left corner).

.Create Object Storage Service
[#img-dash]
[caption="Step 3: "]
image::create-obj-sto.png[Dash,600,200]

WARNING: You can only have one instance of a Lite plan per service. If you already have a Cloud Object Storage Lite,
you'll have to use that one.

===== Creating the Bucket with S3 Interface

After you have created the Object Cloud Storage instance, you can create buckets within it.  You should come to a page
that looks like this.  Click on the 'Create Bucket' button off to the right.

.Create Bucket
[#img-dash]
[caption="Step 4: "]
image::create-bucket.png[Dash,600,200]

On the next page, let's create our bucket.  For the purposes of this tutorial, we're going to call the bucket `mnist-bucket-tutorial`.

IMPORTANT: Set the resiliancy to "Cross Region" and the location to "us-geo". These are not the default settings.

Finally scroll down and click "Create Bucket".

.Setup Bucket
[#img-dash]
[caption="Step 5: "]
image::bucket-settings.png[Dash,600,200]

Note the tabs on the left, and click on "Service Credentials".  You will see a blue box on the right that says "New credential".
 Click on that box.

.Create New Credentials
[#img-dash]
[caption="Step 6: "]
image::create-cred.png[Dash,600,200]

A dialog will pop up. You can leave everything as defaults, however you must add `{"HMAC":true}` into the *Add Inline
Configuration Parameters* box.  Adding this parameter causes the service credential to create `AWS_ACCESS_KEY_ID` and
`AWS_SECRET_KEY_ID`.

After you've created the credentials, you should see them populate in the list in the *Service credentials* page.  Click
on *View credentials* to expose a JSON of the credentials.  In a key called `cos_hmac_keys` you will see `access_key_id`
and `secret_access_key`.  In the directory where you have cloned the tutorial repo, create a file called `set-aws-creds.sh`
and fill it out as follows:

```bash
#!/usr/bin/env bash
export AWS_ACCESS_KEY_ID=<access_key_id>
export AWS_SECRET_ACCESS_KEY=<secret_access_key>
```

Where obviously, you replace `<access_key_id>` and `<secret_access_key>` with the values from the json. Finally at the
command prompt make the bash script executable with

```bash
chmod +x ./set-aws-creds.sh
```

That's it! You've created an S3 bucket on IBMCloud!


==== Installing Kubeflow

Once the cluster is setup (you can check progress in the IBMCloud Web GUI), you have created a bucket, and entered your
credentials into `set-aws-creds.sh`, you are ready to download the MNIST example, install Kubeflow, and submit the MNIST
job for training.


===== Easy Way

The "easy way" to do everything mentioned above is to run the script `once-cluster-is-up.sh`.  This will take care of
everything and even train and serve the model!


===== Instructive Way

Running a one-liner at the shell is not a good way to learn.  You should have an environment variable named `CLUSTER_NAME`
(you can check by running `echo $CLUSTER_NAME` as the command line interface).  We also want to make sure our S3 variables
are set.  Run `source set-aws-creds.sh` to make sure they are infact available as environmental variables.

Once the cluster is up, you will need to set the `KUBE_CONFIG` variable to point at the cluster.


```
ibmcloud cs cluster-config $CLUSTER_NAME
```

will yield a message with something towards the end like `export KUBECONFIG=...`. You can either copy and paste that line
or you can run the following:

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=kubeConfig]
```

which will parse the output of `ibmcloud cs cluster-config ...` find the path to the Kube Config file, and export `KUBE_CONFIG`
appropriately.


====== Clone Kubeflow Examples

We want to clone the Kubeflow examples and revert to a specific commit. We clone into the `kf-tutorial` directory by
running the code:

```bash
git clone https://github.com/kubeflow/examples kf-tutorial
```

We also want to roll back to a specific commit (before a major refactor which happens to break this guide).

```bash
git checkout 4dda73afbfcbf023c20524a4d5dbce011d9dbf79
```

Now the examples code is all set up!

====== Copying the `modified-model-train.yaml` file

IBM run's a modified version of Kubeflow so we have to modify the `model-train.yaml` file in turn.

include::ibm-install-guide/modified-model-train.yaml[tag=customApiSpec]

Where exactly this falls in the yaml and what exactly `ks init` is doing is a bit out of scope for the tutorial (but
will be covered in the book in some detail).  For now simply know and understand that in any YAML that you are using on
IBM, whereever you see `ks init` you need to add the argument, `--api-spec=version:v1.10.11` (or whatever version your
Kubernetes cluster is).  This is because by default the program just asks, "hey what Kubernetes is this" and IBM responds
"It's Kubernetes v1.10.11+IKS", then Kubernetes tries to go download a file at
https://raw.githubusercontent.com/kubernetes/kubernetes/<version>/api/openapi-spec/swagger.json which doesn't exist
(because there is no v1.10.11+IKS, IKS is basically short for IBM-SPECIAL-SAUCE).  So you have to explicitly tell Kube
Sonnet (`ks`) what the actualy version name is.

So at anyrate, get back up to the top directory (maybe a `cd ..` ).  Then copy the `modified-model-train.yaml` to the
Kubflow examples

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=copyMmt]
```

====== Setting up Namespace

First we are going to set a few environmental variables for naming.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=setVars]
```

First we want to create the namespace in Kubernets, and then we will create it in Docker.  Note, that we used the same
name for the namespace, but that is not required and there isn't any particular reason you _need_ to do so.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=createK8sNamespace]
include::ibm-install-guide/once-cluster-is-up.sh[tag=createDkrNamespace]
```

====== Setting Up Kubeflow via Ksonnet

A future chapter will dive into the finer points of what Ksonnet is and what all of these commands are doing. For now
just accept and be happy for these magic commands.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=ksWitchcraft]
```

====== Setting Up the Docker Image

First we will need to configure our Docker registry as follows
```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=configureDockerRegistry]
```

Next we need to build and push a Docker image containing the training code.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=buildnpushDockerRegistry]
```

TIP: You only need to re-push the Docker image if you change the training code.

Finally, IBMs Docker registries are private by default.  This means for your Kubeflow pods to be able to access the Docker
images, they will need to login.  This is accomplished with secrets.  To setup a Docker repository secret for an IBM
private Docker repository, copy the following code.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=createDockerSecret]
```

More information on creating Docker secrets for repositories on IBM in Kubernetes can be found https://console.bluemix.net/docs/containers/cs_dedicated_tokens.html[here].

====== Configuring S3

First we need to set some environmental variables.  These will be passed to `argo` and then to the Docker image we created.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=configureS3]
```

Just as we had to create a Docker secret for the Kube pods to "login" to our private Docker image repository, we must
also create a secret to allow the pods to access files on our S3 which we also created earlier. You might want to confirm
first that `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` are in fact set environmental variables.


```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=createS3Secret]
```

====== Upload Training Data

The last thing we must do before we train our model is uploading the training data.  This can be done via the Bluemix WebUI,
however here we present a handy little trick for uploading it via the command line interface (CLI). This is a for loop that
iterates through the digits 0 through 9 and uploads each.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=uploadData]
```

You may need to copy that into a `.sh` file and run it, or simply run the line

```bash
 aws --endpoint-url $AWS_ENDPOINT_URL s3 cp data/$i.png $S3_TRAIN_BASE_URL
```

ten times where `i` is the numbers 0 through 9.

==== Train a Simple Tensorflow Model

[quote, Most highschool coaches]
Prior preparation prevents poor performance

We've done _so much work_ to set this all up.  Now we reap our reward.  We simply set a few last training meta-variables,
and then run one `argo` command (with several arguments).

First let's set up the arguments.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=setTrainingParams]
```

The user is free to edit `MODEL_TRAIN_STEPS` and `MODEL_BATCH_SIZE`.  Now the moment we've been building too this whole
tutorial. We are now ready to train our model. We can do that with the following `argo` command:

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=submitTraining]
```

That seems like a lot, but we'll get into what all of these commands are doing later in the book. The key is that you now
have successfully trained a model on IBM Cloud. To "see" the model training, you can port forward the `argo-server`
to `localhost` and "watch" the pipeline progress.

```bash
include::ibm-install-guide/once-cluster-is-up.sh[tag=argoServer]
```


==== Serve the Model for new predictions

TODO



=== Azure

=== AWS

==== Prerequisites

Installing Kubeflow on AWS requires you to first create an EKS cluster with GPU instances. Instructions can be found at link:$$https://docs.aws.amazon.com/eks/latest/userguide/create-cluster.html$$. Be sure to also download the AWS CLI at link:$$https://aws.amazon.com/cli/$$ and kubectl at link:$$https://kubernetes.io/docs/tasks/tools/install-kubectl/$$.

When your cluster is ready, update your kubeconfig using the following AWS command:
[source, shell]
----
aws eks update-kubeconfig --name [CLUSTER_NAME] --region [REGION_NAME]
----

Finally, ensure that you can launch at least two GPU instances in your cluster.

==== Configuring your EKS Cluster

Once you have an EKS cluster with at least two worker nodes, run the following command to install Nvidia driver daemonsets:
[source, shell]
----
$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.10/nvidia-device-plugin.yml
----

Verify that the daemonsets are properly installed:
[source, shell]
----
$ kubectl get daemonset -n kube-system

NAME                             DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
aws-node                         2         2         2         2            2           <none>          1m
kube-proxy                       2         2         2         2            2           <none>          1m
nvidia-device-plugin-daemonset   2         2         2         2            2           <none>          1m
----

==== Setting Up Kubeflow

The easiest way to install Kubeflow on an EKS cluster is by using Ksonnet. The tool can be downloaded here: link:$$https://ksonnet.io/#get-started$$.
Next, create a local directory and download the installation files:
[source, shell]
----
mkdir ${KUBEFLOW_SRC}
cd ${KUBEFLOW_SRC}
export KUBEFLOW_TAG=v0.4.0

curl https://raw.githubusercontent.com/kubeflow/kubeflow/${KUBEFLOW_TAG}/scripts/download.sh | bash
----

Finally, install Kubeflow to your cluster:
[source, shell]
----
export KFAPP=kubeflow_app
${KUBEFLOW_SRC}/scripts/kfctl.sh init ${KFAPP}
cd ${KFAPP}
${KUBEFLOW_SRC}/scripts/kfctl.sh generate k8s
${KUBEFLOW_SRC}/scripts/kfctl.sh apply k8s
----

Verify that Kubeflow components are running:
[source, shell]
----
kubectl -n kubeflow get all
----



=== On-prem / different provider
The assumption for on-prem, is that your bare-metal boxes have a Kubernetes installed.
As such, you should be able to reproduce the below shell commands:
[source, shell]
----
$ kubectl cluster-info
Kubernetes master is running at https://<YOUR_K8S_API_IP>
$ kubectl get nodes
NAME                                      STATUS    ROLES     AGE       VERSION
<NODE_1>                                  Ready     <none>    7m        <k8s_version>
<NODE_2>                                  Ready     <none>    7m        <k8s_version>
<NODE_3>                                  Ready     <none>    7m        <k8s_verison>
...
$ kubectl get --all-namespaces services
NAMESPACE     NAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE
default       kubernetes             ClusterIP   <CLUSTER_IP>   <none>        443/TCP         7m
kube-system   default-http-backend   NodePort    <CLUSTER_IP>   <none>        80:31260/TCP    7m
kube-system   kube-dns               ClusterIP   <CLUSTER_IP>   <none>        53/UDP,53/TCP   7m
...
----
The rest of this guide will use Ksonnet, as it functions as a fairly extensible configuration management tool for Kubernetes manifests.

The example below is assuming that your bare-metal boxes run on Linux, but can be tuned and customized for your custom OS.
[source, shell]
----
include::examples/dev-setup/install-ksonnet.sh[tags=installksonnet]
----

Upon install Ksonnet you can now run the following deployment steps to setup a Kubeflow project
[source, shell]
----
include::examples/dev-setup/deploy-kf.sh[tags=deploy]
----

Upon completion of the deployment script you should see a host of CRDs and various resources like the ones shown below, created:

[source, shell]
----
$ kubectl get crds --all-namespaces
NAME                                         AGE
applications.app.k8s.io                      1m
backendconfigs.cloud.google.com              2h
compositecontrollers.metacontroller.k8s.io   1m
controllerrevisions.metacontroller.k8s.io    1m
decoratorcontrollers.metacontroller.k8s.io   1m
notebooks.kubeflow.org                       1m
pytorchjobs.kubeflow.org                     1m
scalingpolicies.scalingpolicy.kope.io        2h
scheduledworkflows.kubeflow.org              1m
studyjobs.kubeflow.org                       1m
tfjobs.kubeflow.org                          1m
workflows.argoproj.io                        1m
$ kubectl get clusterrolebinding --all-namespaces
NAME                                                   AGE
ambassador                                             2m
argo                                                   2m
argo-ui                                                2m
...
----

Once again you can verify that kubeflow components are correctly installed with the following:

[source, shell]
----
$ kubectl -n kubeflow get all
...
----
== Multi-cloud deployments

== Cloud specific Debugging

Once you starting working with a project it's only a matter of time time before you need to start debugging it. We talk about general debugging tools in [[debugging]], but there are some additional tools available on different commercial cloud offerings which may also be of use.

=== Google cloud: stack driver



== Try to not burn down the world / Pointers to avoid reinforcing biases
