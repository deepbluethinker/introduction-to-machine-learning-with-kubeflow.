[[data_and_feature_prep]]
==  Data and Feature Preparation

Machine Learning, especially deep learning, depends on large amounts of data to create models.
While different types of machine learning techniques can handle different kinds of features (e.g. a linear regression model isn't going to be able to work directly with binary image data), data and feature preparation will be an important part of your machine learning.
If you ask machine learning partictioners, many of them spend the majourity of their time working on a combination of data and feature preparation.


Data preparation refers to the act of sourcing the data, augmenting with other datasets, and handling missing/bad/partial records.
This part of the machine learning process can consume a large amount of time, and is often much less fun than the other steps.
That being said, just because this part is not enjoyable does not mean you should give it short shift, high quality data can be the difference
between a successful ML project and a dissapointment.


Feature preparation (sometimes also called feature engineering) refers to the act of transforming the raw input data into features which your machine learning model can use.
Feature preparation often depends on knowledge of both the data and the kind of machine learning algorithms you plan to use.
For example, when training a linear regression model, a common part of feature engineering may be encoding explicit interactions we suspect may be useful, however it is unlikely doing this would benefit a deep-learning model to the same degree.


Both of these processes are best approached iteratively, revisiting them as your understanding of the problem and model changes.
While we examine data preparation and feature preparation seperately, it is not uncommon for these to exist as a single integrated component,
especially in situations where the datasets are less complex.




=== Data Preparation

Data preparation can generally be viewed as two distinct stages: collecting the data, and cleaning/filtering the data.
Often this can be an iterative process later on in the process we may notice the unexpected behaviour in the model, which can be traced back to bad data in our input.
Putting in the effort here to collect both more records and more information about each record here can make huge improvements in your model footnote:[See: The Unreasonable Effectiveness of Data by Halevy, norvid and Pereira, More Data beats Better Algorithms by Tyler Schnoebelen, and many more].

[TIP]
====
Once you've got your data ready, it's important to make sure that future iterations do not have new errors in data introduced. See <<validating_training_data>> for a discussion.
====


==== Deciding on the correct tooling

With two very distinct paths of tooling, making the wrong decision hear can involve substantail changes.
If your input data size is relatively small, a single machine offers you all of the tools you are familiar with.
Larger data sizes tend to require distributed systems, or very large containers.
Even with smaller data sets, distributed systems, like Apache Spark, Flink, or Beam, can do data preparation faster, but can require learning new tools.

You need not use the same tool for all of your data preparation.
This is especially common when working with multiple data sets of different types on which the same tools would be inconvient to use.
A common approach in those situations is to do a first pass data dump into a more accessiable format which your primary tool of choice can work with.
Thankfully Kubeflow Pipelines, introduced in <<pipelines_ch>> , gives you the tools to connect the different steps in an automated manner.



==== Where to put your data between steps

Data preparation in and off its self is not enough for a machine learning solution, so we need to be able to put the output of our data preparation somewhere that it can be consumed later.
In many of the Kubeflow examples, persistant volumes are used to store the data between the data preparation and the next stage.
This is beneficial since it does not depend on a specific storage vendor, however in many situations persistant volumes can be:
// TODO(holden)
slow (TODO link), difficult to scale (TODO link), may require additional set up (link to the mnist seldon example), and on many providers may not support multiple concurrent writers.
While less common in the Kubeflow examples, using the object storage solution of your cloud (e.g. S3/Azure Blob Storage/GCS) may be more suitable.

[WARNING]
====
Using non-kubernetes integrated storage layer does mean that moving your pipeline between clouds can require some changes.
====


==== Single Machine Data Preparation

// Which dataset is the smallest? Let's do the example with that on a single machine.
// Or put in the GH data but from one day

Doing data preparation on a single machine limits the scale of data we are able to handle, but offers the widest range of tools.
If you're an experienced Python programmer a common way to do data preparation is with Jupyter notebooks.

===== Using Jupyter

To get started you can use the Jupyter Hub installation on Kubeflow to begin the development of your data ingestion step, and once it's finished
you can package it into a repeatable container.


The easist way to connect to Jupyter is through the Ambassador Web UI. If you've deployed on GCP a proxy should have been created with the name of your deployment // TODO link.
Otherwise you can use kubernetes port forwarding to access the Ambassador as follows

[WARNING]
====
New version of Docker on Ubuntu default to non-privileged mode which restricts our ability to install packages. If you get permission denied errors re-run the command with `--privileged`.
====

.Connect to the Ambassador

When you go to Jupyter Hub and launch a new notebook you'll be able to select from a list of containers. You'll want to make note of this so that when you're ready to productionize your pipeline you can use a compatible base container.

.Jupyter Launcher Page Image

Once you have a working version of your data extraction pipeline in your notebook you should download it and create a container so it can be run later.

===== Using a custom container

Alternatively if you don't want to use a notebook you can go ahead and directly build your data preparation stage into a container to be run.


With the GitHub dataset we can get the data from Google's BigQuery, but there isn't currently a direct connector between Google's BigQuery and the other tooling we want to use.
To allow the BigQuery to connect to the rest of the tools we want to use, we will create a container to run the BigQuery export into Google's cloud storage system.
To do this we start with making a container which can take in a BigQuery command and dump it's output to a specified container.


Once we have our container created we then need to publish it to a container registry.
We can run the container on Kubeflow with


[NOTE]
====
Google BigQuery is only available on Google cloud. The same result be accomplished on other providers by using Apache Spark directly on the raw JSON dumps.
====




==== Distributed Data Preparation w/Apache Spark


Using a distributed platform make it faster to ingest and process very large data sources.
In Kubeflow, at present, the three data parallel distributed systems available for data preparation are: Apache Spark, Google's Dataflow (via Apache Beam), and link:$http://docs.pachyderm.io/en/latest/fundamentals/distributed_computing.html$[Pachyderm].
For now we will focus on Apache Spark, but many of these data parallel systems have similar concepts if different syntax.

[TIP]
====
We briefly introduce Spark's new Dataset/Dataframe APIs and the tools to load & save your data.
If you want to go beyond the basics we recommend Learning Spark, Spark the Definitive Guide, or High Performance Spark as resources to improve your Spark skills.
====


There are two different ways to get use Spark inside of Kubeflow,
one is with the spark operator component inside of Kubeflow,
and the other is by using a Jupyter notebook with Spark.
In my opinion, a Jupyter notebook is a great place to start to understand your data,
however Jupyter notebooks make important activities like testing and version management more
challenging and can quickly become difficult to maintain.

// TODO: holden -- add an example of using a Jupyter notebook with Spark in Kubeflow

The other way to do this is build a classic program to do your data preparation.
If you've started with a notebook but found it difficult to maintain you can move your notebook into a traditional program.

===== Reading the Input Data

Apache Spark has APIs available in Python, R, Scala, Java; with some 3rd party support for other languages.
We'll use the Python interface due to it's popularity in the machine learning community.
Spark supports a wide variety of data sources, including (but not limited to):
Parquet, JDBC, ORC, JSON, Hive, CSV, ElasticSearch, MongoDB, Neo4j, Cassandra, Snowflake, Redis, Riak Time Series, etc.


Some of the most common data sources are built into Apache Spark and can be loaded directly as with:

// TODO EXAMPLE

However, some data sources (such as X*) require additional settings for Spark to download the data.


Four our GitHub example, the data is stored in big query or as JSON dumps.
Spark directly supports reading JSON, but we can do some pre-filtering in BigQuery SQL on the data to simplify our pipeline.
To access the resulting BigQuery data


===== Validating the schema


===== Handling missing fields

In many situations some of our data will be missing or need computing.
Depending on our dataset we can either fill in those missing data fields with lower quality fields, or compute them, or
if the field is core we can reject records which don't have the required field present.


The GitHub example does a combination of all 3 of these.


===== Filtering out bad data

Detecting incorrect data can be challenging, however without it

===== Joining and augmenting the data


===== Saving the output

Once you have your data ready it's often time to save the output. If you're going to use Apache Spark to do your feature preparation you can build a program to do both.
If, after filtering, the amount of data is relatively small and you wish to use a persistant volume to save your data you can bring the data back to the driver program by calling `collect()` and saving it as a regular collection.
If your data is large, or you otherwise want to use an object store, Spark can write out to many different format just as in the loading.
The correct format will depend on the tool you intend to use for feature preparation.



=== Feature Preparation

==== Using TFX / Tensorflow Transform


The Tensorflow community has created an excellent set of integrated tools for doing data preparation.
At present these tools are all built on top of Apache Beam and have limited support for distributed processing outside of Google Cloud.
However if you have relatively small datasets these tools can be used regardless of where your Kubernetes cluster is deployed.


[TIP]
====
Apache Beam's support for Apache Flink is under active development and _could_ mean that future versions are able to work outside of Google Cloud.
====


==== Using Apache Spark

Apache Spark has a large number of built in feature preparation stages that you can use


[TIP]
====
While we've looked at using Apache Spark for feature prep you can also use it for training and serving a variety of machine learning models we explore in <<spark_ch>>
====

=== Conclusion

Now you have the skills to get your data ready for doing machine learning on.
As you approach the next chapters you will have a choice of choosing which kind of tools you want to build your model with.

