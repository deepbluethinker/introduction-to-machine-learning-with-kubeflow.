[[simple_training_ch]]
== Hello Kubeflow

Welcome to your first steps into the exciting world of Kubeflow! This example will cover a lot of ground, and for a fair
bit of it- it might seem like we are instructing you to mindlessly enter commands. For this example we just want to help you
get your first model up and running.  We assume you're doing this on a local machine for testing, and that you have a bit of
familiarity with Kubernetes.   While we will point you to the config files and Docker containers that are driving all of this,
they are not the focus of this chapter.  The focus of this chapter is to provide an end to end example that you can follow along
with at home.  In future chapters we will dig in to the "why" of everything we're doing, we promise.

For now just enjoy the ride.

=== Setup

We assume the user has the following already installed:

* Kubernetes, v1.13.3
* Helm, v2.13.0
* KSonnet, v0.13.1
* Argo, v2.2.1
* Kubeflow, v0.4.1

If you don't have all of these requirements already installed, please install them first.

==== Creating Our First Kubeflow Project

Before we get started, we will need to make a Kubeflow project for us to work in.
The script `kfctl.sh`, in the scripts directory of your Kubeflow installation,
allows you to create projects. We'll start with an example project in <<create_example_project>>.

[[create_example_project]]
.Create first example project
====
[source, shell]
----
include::examples/ch2_seldon_examples/setup_example.sh[tags=generate_kf_app]
----
====


[NOTE]
====
If you haven't added the scripts directory to your path for easy access you will need to to use the full path to your Kubeflow install.
====

[NOTE]
====
Trevor's note to himself on things that need to be checked, but not for final version: This fails with `ERROR handle object: patching object from cluster: merging object with existing state: unable to recognize "/tmp/ksonnet-mergepatch923988339": no matches for kind "Application" in version "app.k8s.io/v1beta1" `... But always works on round 2
====

==== Setting Up Components

Kubeflow project's can have all kinds of different components.
Many common ones, like seldon, are installed by kfctl automatically.
In addition to the default components set up we will configure a few extra pieces:

[[setup_components]]
.Set up components
====
[source, shell]
----
include::examples/ch2_seldon_examples/setup_example.sh[tags=setup_components]
----
====

In <<setup_components>> are first setting up `helm` which is an application package manager on Kubernetes (`tiller` is the `helm`
server).  Next we use `helm` to install `seldon-core-analytics` and the `grafana` charting package on Kubeflow. This will give
us some pretty charting to real time manage our models.

==== Cloning the Example


For this simple example we are going to follow along with an example you can find at https://github.com/kubeflow/example-seldon.

The example source can be cloned with git <<get_seldon_example_source>>.

.Clone Seldon Example
[[get_seldon_example_source]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/setup_example.sh[tags=cloneSeldonExample]
----
====


==== Creating a Persistent Volume

Kubeflow is a system that decouples the training and serving of models. In other words, models are trained in one
container and served in a different container.  The actual trained model must be shared from the container that trains
the model to the container that is serving it.  There are several ways to achieve this goal, but the easiest is a
`PersistentVolume`.  A `PersistentVolume` is an allocation fo disk space that survives beyond a pods lifecycle.

The example we just cloned (<<get_seldon_example_source>>) used an https://kubernetes.io/docs/concepts/storage/volumes/#nfs[Network File System (NFS) Mount].
  While this is an ideal way to share information between systems in production, it is a bit complicated to set up "locally"
  (read `minikube` or `microk8s`).  We have updated the example to use a `local` mount. Please note, if you using GCP to
  do this example, you can skip this step.  This step is only to create a local `PersistentVolume` and
  `PersistentVolumeClaim`

While the user is encouraged to https://kubernetes.io/docs/concepts/storage/persistent-volumes/[learn more] about the various options of `PersistentVolumes` it will be sufficient for
this example to follow the steps below to simply create one.

To create the `PersistantVolume` and `PersistantVolumeClaim` see <<create_pv>>.


.Create Persistent Volume Example
[[create_pv]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/setup_example.sh[tags=createPV]
----
====



The first command will create a `PersistentVolume`.  The second command is a request by a user for a
piece of the storage allotted in the `PersistentVolume` which can then be mounted to a pod.  We must have a `PeristentVolume`
from which a `PersistentVolumeClaim` can be made.

If that whole paragraph feels like I'm talking in circles- that's OK for now. Here is the important thing you need to
understand:

NOTE: The `PeristentVolumeClaim` is where the trained model is stored, and then loaded for serving.


=== Training and Deploying a Model

In traditional "machine learning" texts, this phase is the one that is given the most attention, with a few simple
examples on deployment, and very little treatment on model management.  In this text however, we assume chosing what
algorithm/model to use is either something the practitioner is very familiar with or not the practitioners job.

==== Building a Training Image

Let's head back to the
`example-seldon/models/sk_mnist/train` directory.  In this directory you'll see a Dockerfile, and `create_model.py`.
`create_model.py` download the MNIST dataset, train a RandomForrestClassifier on the data within, and save
the trained model to `/data/sk.pkl`, which is our `PersistentVolumeClaim`.   The Dockerfile installs `requirements.txt`
and waits for `/data` to be mounted before running `create_model.py`.

While this process is intersting, and worth taking a look at, it is not required for this simple example.  We only point
it out to show that there is no magic happening here, and to give the reader a preview of things to come.

==== Training and Monitoring Progress

The next step is to train the model.  This is done via an `argo` workflow.  This will take the training container we just
discussed, and launch it in the cluster. There are various reasons for wanting to conduct training on a cluster instead
of a laptop including, the data exists in a place adjacent to the Kubernetes cluster or you need more power than your laptop
can provide, to name a few.

In the <<create_training_workflow>>, we see how to submit the model training workflow with `argo`.

.Create Training Workflow Example
[[create_training_workflow]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/tagable_bs.sh[tags=createTrainingWorkflow]
----
====

There are two ways to "monitor" the progress of training.  The simplest is to do so via the CLI (Command Line Interface). If the later GUI methods
don't work for you, please don't fret- simply 'watch' the progress via the command line interface as is shown in
<<monitor_training_workflow_cli>>.

.Monitor Training Workflow Example
[[monitor_training_workflow_cli]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/tagable_bs.sh[tags=cliTrainingCheck]
----
====

The CLI is a perfectly acceptable way to monitor a job, but there is a prettier option available.

CAUTION: There are as many ways for this next part to go wrong as their are places to deploy Kubernetes (i.e. as there
are stars in the sky).  The important thing is that your model trains.  Try this next part but if it doesn't work, that
is OK. Don't get hung up here.

You can go to the `ambassador` UI, and add `/argo/` to the end of the URL. If you are running Kubernetes in `minikube` or
`microk8s`, you will need your IP address (or your VMs IP address), and the `ambassador` port.  To get your `ambassador`
port follow <<get_ambassador_port>>.

.Getting Ambassador Port Example
[[get_ambassador_port]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/tagable_bs.sh[tags=getAmbassadorPort]
----
====

The URL you want is http://<machine_ip>:<ambassador_port>/argo/

For me that is http://10.53.148.167:30134/argo/  The observent reader will notice, that the `ambassador` IP address listed
in the prior example, is not the same as the machine IP address.

If everything goes correctly (and it's OK for now if it doesn't), you will see something like this.

.Argo WebUI
[#img-argo]
[caption="Figure 1: "]
image::images/ch2_argo_screenshot.png[argo-ui,width=909,height=510]

The `argo` web user interface (UI) is a way to monitory how your model training is progressing. In future chapters we will introduce
you to `pipelines`, which are a wrapper around `argo`.  The web UI isn't super helpful at diagnosing why training failed,
but it is a thing you can look at to monitor weather or not a job has succeeded.


==== Building and Deploying Model Serving Images

As stated earlier, Kubeflow decouples model training and serving.  Consider the following scenarios:

1. A simple model, on a small dataset, serving only on the local machine.
2. A simple model, on a large dataset, serving to a large production system.
3. A complex model, on a large dataset, serving to a rapidly scaling number of users.
4. A complex model, on a large dataset, serving only to a small number of users.
5. A set of models that need to be managed and swapped out of live production systems.

Models can be simple or complex, datasets can be prohibitivly large or trivially small, serving can be to a small or large
number of users and may need to scale back and forth. Finally, models don't last forever, their value degrades over time.
Kubeflow is an ideal system for all cases but number one above (it would still work for number one, its just a bit overkill).

The serving layer of Kubeflow is based on something called `seldon-core` which the user is (as always) encouraged to https://www.seldon.io[read
more about on their own].  Seldon allows users to scale model serving deployments up and down on Kubernetes in response to
variable amounts of load, as well as do A/B and multi-armed bandit testing.


As with the other workflow yamls, the details and specifics aren't important at the moment, however the user is free and
encouraged to https://github.com/kubeflow/example-seldon/blob/master/workflows/serving-sk-mnist-workflow.yaml[inspect the yaml for familiarity]
as well as the https://github.com/kubeflow/example-seldon/tree/master/models/sk_mnist/runtime[source files].
Seldon uses a program called https://github.com/openshift/source-to-image[`s2i`] to package the model into a Docker image,
however we don't need to build this as a prebuilt version exists in DockerHub. See the <<model_serving>> for how to do this.

.Submitting Model Serving Workflow Example
[[model_serving]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/tagable_bs.sh[tags=submitSeldon]
----
====


TIP: `-p deploy-model=true` is a feature of this particular workflow, but not necessary for all kubeflow serving.

To check that the serving layer is running you can follow the same steps as in checking the progress of the training model
(last section)

1. `kubectl get pods -n kubeflow | grep sk-deploy`
2. `argo list -n kubeflow`
3. Check the WebUI


==== Test Query

Finally, lets examine how to query our model and monitor the results it is producing. Always a good step to sanity check
new models when you put them into a production (or quasi-production) environment.


Recall the `ambassador` port you got earlier when trying to get to the `argo` WebUI.  We're going to need that and the machine
IP again.  If you weren't able to log on to the `argo` UI, this machine might not be reachable or something else might be
configured wrong.

The model will be available at http://<MACHINE_IP>:<AMBASSADOR_PORT>/seldon/mnist-classifier/api/v0.1/predictions .

There is a python https://git.atlas.oreilly.com/oreillymedia/introduction-to-machine-learning-with-kubeflow/raw/master/examples/ch2/query-endpoint.py[script available]
 for pulling an image from the MNIST dataset, turning it into a vector, displaying the image, and sending it to the model.
  The <<model_serving>> is a fairly clear python example  of how one can query the model. The model returns a json of
  the 10 digits and the probabiltiy of weather the submitted vector represents a specific digit.  Specifically we need
  an image of a handwritten digit which we can turn into an array of values.

.Model Query Example
[[model_serving]]
====
[source, python]
----
include::examples/ch2/query-endpoint.py[tags=scriptGuts]
----
====

For example, the handwritten '3':


.Handwritten '3'
[#img-3]
[caption="Figure 2: "]
image::images/ch2_query-image.png[argo-ui,909,510]


returns the following:

```
{'data': {'names': ['class:0',
                    'class:1',
                    'class:2',
                    'class:3',
                    'class:4',
                    'class:5',
                    'class:6',
                    'class:7',
                    'class:8',
                    'class:9'],
          'ndarray':[[0.03333333333333333,
                      0.26666666666666666,
                      0.03333333333333333,
                      0.13333333333333333, ## It was actually this
                      0.1,
                      0.06666666666666667,
                      0.1,
                      0.26666666666666666,
                      0.0,
                      0.0]]},
 'meta': {'puid': 'tb02ff58vcinl82jmkkoe80u4r', 'routing': {}, 'tags': {}}}
```

We can see that even though we wrote a pretty clear '3' the model's best guess was '7'. That being said, `RandomForrestClassifier`
is a bad model for handwriting recognition- so this isn't exactly a shock.

In addition to monitoring that the workflow has successfully run in `argo` we can also use `grafanna` to observe how much
useage and other model metrics. We can log onto the following webs address with the user id `admin` and the password `password`.


**todo how to get grafana port**
http://<MACHINE_IP>:<GRAFANA_PORT>/dashboard/db/prediction-analytics

**todo screen shot**


Because we are (probably) scaling this model up for production, we may also wish to loadtest our model. We can see how simply
this can be done in the <<load_test>>.

.Load Testing Example
[[load_test]]
====
[source, shell]
----
include::examples/ch2_seldon_examples/tagable_bs.sh[tags=loadTest]
----
====



=== Conclusion

We hope that your first adventure into Kubeflow has been a success.
In the next chapter we are going to introduce the case studies that we will develop
throughout the rest of the book.
