[[case_studies]]
==  Introducing our case studies


Machine learning can happen on many different types of data, and the approaches and tools may differ.
For the rest of the book, when possible, we will use data from these three case studies to explore Kubeflow and some of it's components.



=== GitHub Data

GitHub is one of the largest open collections of source code, and the wonderful folks at link:$https://www.gharchive.org/$[GH Archive] have created and archive of all of the public interactions on GitHub.
This data has been used for many interesting machine learning projects, including
link:$https://towardsdatascience.com/how-to-create-data-products-that-are-magical-using-sequence-to-sequence-models-703f86a231f8$[issue summarization] and
link:$https://githubengineering.com/towards-natural-language-semantic-code-search/$[semantic language code search] both with Kubeflow.
Using the public link:$https://www.gharchive.org/$[GitHub archive dataset] we will explore training two different models: one to generate "good" commit messages and another to predict chunks of code likely to result in a comment.


This dataset is available to us in two different ways.
The raw dataset is stored as json records on `data.gharchive.org`, and also loaded into link:$https://developers.google.com/bigquery/$[Google BigQuery]
as a link:$https://bigquery.cloud.google.com/table/githubarchive:day.20150101$[public dataset] we can write SQL expressions against.


=== Financial Data (Order Book)

=== IoT Data (Sugar Creek Brewery)

Have you ever considered how much science and engineering goes into your favorite craft brew? Macro brewers have been
to use finely tune the volume of liquid, CO2, temperature, and other variable to optimally fill a bottle with minimum
waste, however for smaller craft brewers, having runs of only a week or less, this is somewhat more tricky.  Luckily,
with the advent of cheap sensors, math, and buzzwords craft brewers are able to optimize their fills very quickly,
reducing waste and allowing them to stay competitive with macro-brewers.

In this example, we will be looking at data
from link:$https://sugarcreekbrewing.com[Sugar Creek Brewing Company]'s production lines, looking at how we would
determine optimal values of various input paramters for a new run of beer, and how to quickly detect if there was a fill
error in a bottle downline. (Quickly detecting a fill error before the label is applied results in significant savings).






=== Conclusion

These case studies will continue throughout the book, with each one showing you how different and similar ML pipelines can be.
